---
layout: post
title: 2주차
---

## 이재홍 : 119 ~ 182 (3.1.5절)


# 비용기준 옵티마이져

  비용기준 옵티마이져는 관계형 데이터베이스가 추구하는 이상형

  미리 작성해둔 다양한 통계정보 참조(통계정보의 형태와 종류는 DBMS마다 상이)

  통계 정보엔 한계존재 -> 통계적 확률을 이용하기 때문에 오차 발생

  - 비용기준 옵티마이저 장점
    1. 현실을 감안한 최적화

       가장 중요한 정보는 분포도 -> 분포도를 정확히 알아내기 어려움 -> 옵티마이져의 한계

       이를 해결하기 위해 컬럼값의 범위별로 분포도를 보유, 분포도의 종류는 버킷에 따라 결정

       * 최대치와 최소치에 대한 균등 범위 분할(컬럼값이 적거나 분포도의 편차가 심하지 않을 경우): 넓이균형 히스토그램
       * 로우수를 버킷수로 나누어 분할(분포도의 차이가 심한 경우, 존재하지 않는 컬럼이 많을 경우): 높이균형 히스토그램

       일반적으로 분포도나 컬럼값의 편차가 심할 경우 판단에 문제가 많으므로 높이균형이 유리

       DBMS별 옵티마이져에 따라 방식이 정해져 있으며, 제공 프로시저를 활용하여 통계학적으로 적절한 수치의 자동 결정이 바람직

    2. 통계 정보의 관리를 통한 제어

       통계정보를 수집할 대상과 갱신 주기 등에 대한 적절전략을 수립

       DBMS가 제공하는 '테이블 모니터링 기능'을 사용하는 것이 가장 좋음 -> 모든 테이블이 다르므로 모두 다른 방법이필요

       * 통계정보의 잦은 갱신은 오버헤드가 발생하므로 주의 필요
       * 이미 최적의 경로를 안다면 힌트로 고정시키는 방법도 바람직

    3. 최악의 상황이 발생할 확률이 감소

       옵티마이저가 '이미 존재하는 논리 중' 최적의 경로를 찾아주기 때문

  - 비용기준 옵티마이져의 단점
    1. 실행계획 예측이 곤란
       
       인덱스/테이블을 재생성 또는 SQL을 재구성하거나 통계를 갱신하거나 갱신하지 않을 경우  실행계획이 유동적으로 변경됨

    2. 버전에 따른 변화

       최적화 기준의 변화로 실행계획이 변경되는 경우

       적절한 SQL을 구사하고 전략적인 옵타마이징 팩터 전략 수립 필요

    3. 실행계획 제어가 곤란

       쿼리를 필요에 따라 변경하거나 다양한 요소를 감안하여 실행계획을 수립하기 때문에 제어가 곤란

  - 옵티마이져의 발전방향
  
    발전해가는 방향은 비용기준임이 확실

    현재는 비용기준으로 통일되어 가고 있으므로 통계정보를 관리하는 많은 기능들이 필요

    단위 SQL보다는 테이블/인덱스 단위로 관리하는 등의 편의를 고려한 방법으로 높은 확률의 최적화를 

    유도해가는 것이 지향하는 방향이자 전략

  - 통계정보 관리를 위한 제언

    통계정보를 관리하는 것은 개발자보다는 설계자, 데이터 아키텍트(DA)의 레벨에서 하는 것이 바람직

    과거에는 I/O 즉, 물리적 처리량 만으로 통계정보를 산정

    최근에는 CPU 사용량 등도 추가하여 정확도 상승 

    -> 옵티마이져가 시스템 통계를 통해 보다 정확한 환경을 파악함으로서 환경에 맞는 수행환경을 제공하는 것이 가능

       예) OLTP/배치의 수행환경 구분 등

    통계정보의 수집엔 DBMS에서 제공하는 패키지를 이용하는 것을 권장

    데이터가 많은 경우 부하가 많을 수 있으므로 견본 데이터를 이용하여 수집하는 것도 가능(5%권장)

    병렬 처리도 가능

* 옵티마이져 목표의 선택

  옵티마이져가 수행하는 최적화는 시뮬레이션

  최적을 평가하는 기준에 따라 결과가 달라짐

  - 옵티마이져 모드의 종류

    1. 초기결과 최적화(FIRST_ROWS) - 마라톤과 비슷 1등이 최고! = CHOOSE 모드와 비슷

       비용기준과 경험적 방법을 혼합((비용 + 규칙기준)이었던 과거 버전과 양립하기 위함)

    2. 전체결과 최적화(ALL_ROWS) - 구보 낙오자 없이 -> 비용기준 최적화

    3. 커트라인(Cut line) 지정(FIRST_ROWS_n) -> 비용기준 최적화

    기본은 ALL_ROWS이지만 OLTP성 업무가 많은 현실에서는 FIRST_ROWS가 옳을 수도 있지 않을까?

  - 옵티마이져 모드의 결정기준

    1. OLTP성 업무의 경우 과거 CHOOSE 모드 있을 시 개발된 시스템은 FIRST_ROWS가 적합, 신규 버전일 경우 FIRST_ROWS_n이 적합

    2. OLAP형 Batch 처리 서비스는 ALL_ROWS가 유리

    옵티마이져 모드를 운영중에 변경하는 것은 매우 위험

    변경하기 위해서는 사전 준비를 통해 영향도를 줄여야 함

    실행계획을 고정하기 위한 2가지 방법

    * 초기 설정 파라메터에 과거 사용 버전을 지정
    * 실행계획 요약본을 작성하여 이를 참조하도록 하는 OUTLINE을 이용하는 방법

  - 규칙 기준을 비용기준으로 넘어가는 추세에서 기존 CHOOSE 모드에 대응되는 대책이 필요

    * 동적 표본화(Dynamic sampling): 소량의 표본을 동적으로 추출하여 통계정보로 활용, 이 기능을 적용하면 매번 수행되므로 빈번하게
      수행되는 경우에는 적용하면 안되나, 그 외의 경우에는 적용할 가치가 있음
    * 잘 동작하는 실행계획은 고정 할 필요가 있음

* 실행계획 고정화(Stability)

  - 아웃라인(OUTLINE)

    * 과거에 수행되었던 실행계획의 요약본을 저장하고 있다가 이것을 참조하여 실행계획을 수립하는 것
    * 아웃라인을 지나치게 사용하여 더 좋은 퍼포먼스 발휘의 가능성을 차단하지는 말아야 함.
    * 범용적/개별적으로 관리 가능하며 적용/금지 설정 및 강제 편집 등이 가능
    * 그룹으로 지정하여 관리 할 수 있으므로 상황별 적용이 가능(주간/야간 환경 변경, 서브시스템 등)
    * 옵티마이저 업그레이드 시 적용
      
       갑작스러운 기준 변화는 시스템에 큰 지장을 초래

       1. 규칙기준 -> 비용기준: 아웃라인 생성 후 통계수집 후 모드를 CHOOSE로 설정하여 일부에 아웃라인을 적용

       2. 버전업의 경우: 아웃라인을 생성 후 어플 테스트를 하여 문제가 있는 부분에 아웃라인을 적용

    * 문제 발생 SQL 들의 아웃라인 생성 후 그룹핑 하여 관리 하는 방법도 가능

* 옵티마이져의 한계

  - 완벽할 수 없는 통계정보로는 정확한 처리 범위를 예측 할 수 없음

  - 결합된 컬럼에 대해 일일이 분포도를 보유할 수 없음

  이에 대한 해결책으로 다양한 사용형태를 만족할 수 있는 종합적이고 전략적인 차원에서 적절한 인덱스나 클러스터링을 결정하고 수준높은 SQL을 구사

* 옵티마이져의 최적화 절차

  궁극적 목표는 사용자가 요구한 결과를 최소한의 자원으로 처리하는 방법을 찾는 것

  옵티마이져는 SQL문을 보유하고 있는 각종 스키마 객체(Index, Table 등)들에 대한 정보를 토대로 가장 효율적인 형태를 선택

  - SQL 실행 -> 데이터 베이스 딕셔너리를 이용하여 파싱 -> 파싱 절차를 토대로 적용가능 실행계획 선별 -> 힌트를 감안하여 실행계획 생성

  - 실행계획을 선별할 시 통계정보를 기반으로 선택

  - 가장 비용이 적은 실행계획 선택이 최선의 방법은 아님

* 옵티마이져의 구성

  - 질의 변환기

    보다 양호한 실행계획을 얻을 수 있도록 SQL의 모양을 변경하는 모듈

    1. 뷰병합

       뷰를 쿼리로 대체하여 뷰를 사용함으로 발생되는 불이익을 없앰

    2. 조건절 진입

       뷰병합이 어려운 경우 엑세스 쿼리의 조건절을 뷰쿼리 내부에 추가 하는 것

    3. 서브쿼리 비내포화

       서브쿼리를 가능할 경우 조인으로 변경

    4. 실체뷰(Meterialized view)의 쿼리 재생성

       확장된 뷰병합으로도 볼 수 있으며 가장 최적의 물리적 집합을 처리하도록 쿼리를 재생성

    5. OR 조건 전개

       OR 조건 연산자가 처리주관 조건의 역할을 한다면 여러 개의 단위 쿼리로 분기하여 UNION ALL로 연결, 비용을 계산 및 비교하여 전개여부 결정

    6. 사용자 정의 바인드 변수 엿보기(Peeking)

       조건절에 바인드 변수가 있을 때 최초로 수행된 변수로 실행계획 생성 후 공유

  - 비용 산정기

    옵티마이져는 비용산정을 위해 선택도, 카디널리티, 비용을 측정

    서로 연관되어 있으며 필요에 따라 관련된 예상치 생성

    1. 선택도(Selectivity)

       처리할 대상집합에서 해당 조건을 만족하는 로우가 차지하는 비율

       선택도를 판정하는 단위는 개별 컬럼 조건이 아닌 해당 엑세스를 주관하는 조건들의 모임

       각 통계정보를 활용하여 산정, 통계학적 연산을 통해 구하기 때문에 오차 존재

       히스토그램이 없다면 동적 표본을 이용해서 수립, 있다면 보다 정확한 근거를 가지고 계산될 수 있음

    2. 카디널리티(Cardinality)

       판정대상이 가진 결과건수(선택도 X 전체 로우수)

       같은 대상 집합에 대해서는 비율만으로 충분하나 조인의 순서, 방향 등을 결정하기 위해 절대량을 판단하기 위해 필요

    3. 비용(Cost)

       실행계획 상의 연산들을 수행할 때 소요되는 시간 비용을 상대적으로 계산한 예측치. 통계정보에 CPU, 메모리, I/O 고려

       옵티마이져의 가정들이 옳지만은 않기 때문에 잘못된 비용산정의 한계가 있으며 이를 보완하기 위해 다양한 힌트 및 초기화 파라메터가 추가되고 있음

  - 실행계획 생성기

    주어진 쿼리를 처리할 수 있는 적용 가능한 실행계획을 선별하고 비교검토를 거쳐 최소의 비용을 가진것을 선택하는 모듈

    * 부속 서브쿼리, 병합 불가능한 뷰들의 실행계획 생성(이 결과가 메인 쿼리에 절대적인 영향을 받기 때문에 먼저 생성)

      가장 깊은 곳에서 부터 우선적으로 최적화를 수행

    * 실행계획 생성기는 논리적으로 모든 비교평가를 하지는 않음

      각 상황별로 적절한 비교평가를 위해 적응적 탐색과 경험적 기법에 대한 초기치 선택(Cut off)하는 전략 사용

      1. 쿼리 수행에 예상되는 총 수행시간에 비해 최적화에 소요되는 시간이 일정비율을 넘지 않도록 탐색하는 전략

      2. 탐색도중 최적이라고 판단되면 탐색을 멈추는 전략

      추가로 자습적 기법을 통해 최적이거나 최소한 아주 좋은 것이라 판단되는 것들을 선별 후 선택

      힌트를 통해 보완을 해야 함

* 질의의 변환(162p)

* 이행성 규칙

  - A=B and B=C 이면 A=C

    -> 이를 통해 보다 유리한 조건을 적용할 가능성이 높아짐

    -> 비교하는 대상이 상수 수식이 아닌 경우 이행이 일어나지 않음

  - OR 조건 -> UNION ALL로 분기

    -> 기본적으로 여러 개로 분기된 경우 불필요한 엑세스가 있다면 이행 하지만 비용을 비교하여 취사선택함

  - 서브쿼리 -> 조인으로 변경

    -> 조인으로 변경하여 유리한 실행계획이 선택될 수 있도록 함
 
    -> 불가능한 경우 서브쿼리 부터 실행하거나 필터링, 해쉬/머지 조인으로 수행

* 뷰병합(169p)

  뷰와 인라인 뷰 등을 사용할 경우 엑세스 쿼리의 조건절이 실행계획을 선정하는데 영향을 못주지만 뷰병합을 통해 엑세스 쿼리의 조건절이 반영된 실행계획 생성

* 사용자 정의 바인드 변수의 엿보기(Peeking)

  바인드 변수가 사용된 SQL의 경우 최초에 수행되는 파싱이 일어날 때 사용된 변수에 대해 실행계획이 수립되는 것

  평균적인 분포도로판단한 경우 희석되는 변수들이 선택될 수 있으나 극단적인 편견이 발생될 수 있음

  이 경우 실행계획은 문제가 없으나 실제 수행에서는 문제가 발생할 수 있음

* 개발자의 역할

  SQL을 잘 활용하는 방법을 익혀두는 것이 필요

    


   


## 김창수 : 183 ~ 260 (3.2.3절)
### 3.2 실행계획의 유형
*실행계획의 형태별 기본형에 대한 개념과 내부의 처리과정을 정확히 이해하는데 초점*

** 실행계획의 유형 **
* 스캔을 위한 실행계획
* 데이터 연결을 위한 실행계획
* 각종 연산을 위한 실행계획
* 기타 특수한 목적을 처리하는 실행계획

#### 3.2.1 스캔의 기본유형
*Scan : 실제로 물리적인 데이터를 찾아서 액세스하는 것!*
* Full Table Scans
* Rowid Scans
* Index Scans
* Cluster Access
* Hash Access
* Sample Table Scans

##### 3.2.1.1 Full Table Scans
*테이블의 모든 rows를 읽어 들인다. index scans과 **손익분기점**이 커진다면 Full Scan이 유리할 수도 있다*

옵티마이저가 Full scan을 선택하는 경우
1. 적용가능한 인덱스의 부재
2. 넓은 범위의 데이터 액세스
3. 소량의 테이블 액세스
4. 병렬처리 액세스
5. FULL 힌트 적용

#### 3.2.1.2 Rowid Scans
*Rowid는 그 로우를 포함하고 있는 데이터파일과 데이터 블록, 그리고 블록 내에서의 위치를 가지고있다. 그러므로 단 하나의 로우를 테이블에서 추출하는 가장빠른 방법이다.
대부분의 Rowid scan은 인덱스를 경유하여 테이블을 액세스하는 과정에서 발생한다.*

#### 3.2.1.3 Index Scans
*인덱스를 통해서 물리적인 데이터를 찾아서 액세스*
* Index Unique Scan
* Index Range Scan
* Index Range Scan Descending
* Index Skip Scan
* Full Scan
* Fast Full Index Scan
* Index Join
* Bitmap Index

1. Index Unique Scan
	* 대부분(?) 단 하나의 Rowid를 추출한다.
	* 인덱스가 Pk 이거나 Unique Index로 생성되어 있어야한다.
	* 인덱스 구성된 모든 커럼들이 '='로 비교되어야한다.
2. Index Range Scan
	* 가장 보편적인 데이터 액세스 형태이다.
	* 최초 시작점을 찾을 때만 랜덤 액세스를 사용하고 그 다음부터 종료시까지 스캔한다. 
	* 인덱스 스캔을 하더라도 범위가 넓어짐에 따라 부하가 증가하는 것은 **인덱스의 rowid로 테이블을 랜덤 액세스 해야 하기 때문**이다. 
	* unique index, non-unique index 모두에서 발생할 수 있다.
3. Index Range Scan Descending
	* 역순으로 데이터를 액세스 한다는 것을 제외한다면 index range scan과 동일하다.
	* 인덱스의 역순으로 order by 될때 옵티마이져의 판단에 따라 일어난다.
4. Index Skip Scan
	* 인덱스 선행컬럼이 사용되지 않더라도 각각의 분기된 가지 별로 후행컬럼으로 스캔한다.
	* 선행컬럼의 카디널러티가 낮을때 의미가 있다.
5. Index Full Scan
	* 조건절에서 반드시 인덱스 선행컬럼이 사용될 필요는 없지만, 인덱스 컬럼이 적어도 하나이상 사용되었을때 적용이 가능하다.
	* 인덱스 컬럼중 not null 컬럼이 하나는 존재해야한다.
	* order by 를 하려는 요구를 어떤 인덱스를 사용함으로써 가능하다면 사용 할 수 있다.
6. Index Fast Full Scan
	* 쿼리에 사용된 컬럼이 모두 인덱스에 포함되어 있다면, FFS은 전체테이블 스캔의 대안으로 사용될 수 있다. 
	* 인덱스 컬럼중 not null 컬럼이 하나는 존재해야한다.
	* 비트맵 인덱스에서는 적용 할 수 없다.
7. Index join, Bitmap Index는 별도의 장에서 설명

#### 3.2.1.4 B-Tree Cluster Access
*두가지 클러스터링 형태 즉 1. 대량의 범위처리의 효율화를 목적으로 한 단일 테이블 크럴스터링, 2. 조인의 효율적인 연결읠 위한 두개 이상의 테이블을 하나의 클러스터에 저장하는 방법으로 클러스터 키를 통한 접근방법.*
* 클러스터 키를 통해 스캔하므로 랜덤 액세스를 최소화 할 수 있다.

#### 3.2.1.5 Hash Cluster Access
*해쉬값을 이용하여 클러스터링하는 방법*
* 동일한 해쉬값을 가진 데이터를 동일한 블럭 내에저장하여 클러스터링 팩터를 높인다ㅏ.
* 인덱스를 이용한 데이터 액세스는 인덱스 I/O와 테이블 I/O를 거쳐야 하지만, 해쉬함수를 생성하는것과 테이블 I/O로만 구성되므로 I/O를 줄 일 수 있다.
* 테이블의 크기가 작어서 메모리 적중률이 높다면 Index Unique Scan이 유리할 수도 있지만, 적중률이 낮은 대용량 테이블의 랜덤 액세스에서는 약 30% 정도의 개선효과가 있다.
* 생성시에 미리 물리적 디스크 공간을 확보하므로 데이터의 증가가 심하게 발생하는 경우에는 적절하지 않다. 
* OverFlow Block이 발생한다.
* 법위연산(대소, like 등)에는 적용이 불가능
* 우편번호나 시스템 사용자 정보 등에 적합

#### 3.2.1.6 Sample Table Scan
*테이블의 데이터 중에서 사용자가 부여한 비율 만큼의 데이터를 읽고, 그 중에서 조건에 만족하는 로우들을 리턴한다.*

아래의 경우 사용 가능
* 데이터 마이닝 - 여론조사
* 데이터 정제 - 오류패턴
* 테스트를 위한 표본데이터 생성 

### 3.2.2. 데이터 연결을 위한 실행계획
*조인의 기본적인 처리절차*
* Nested Loops Join
* Sort Merge Join
* Hash Join
* Semi Join
* Cartesian Join
* Outer Join
* Index Join

#### 3.2.2.1 Nested Loops Join
*어떤 범위의 집합(Outer)의 각 로우에 대하여 연결고리를 통해 반복적으로 다른 집합(Inner)의 대응되는 로우를 탐침(Iteration)한다.*
* **먼저 수행되는 집합의 처리범위가 전체의 일량을 좌우한다.**
* **나중에 반복 수행되는 연결작업이 랜덤 액세스로 발생한다.**
* 소량의 범위를 연결할 때는 매우 유용하지만 대량의 범위는 커다란 부하를 가져올 수 있다.
* 214 plan 참조
* Advanced nested Loops Join - 215페이지 참조

#### 3.2.2.2 Sort Merge Join
*조인의 대상 범위가 넓을 때 발생하는 랜덤 액세스를 줄이기 위한 경우나 index join 이 되지 않을 때를 해결하기 위해 사용*
* 연결을 위해 랜덤 액세스를 하지 않고 스캔을 하면서 이를 수행한다.
* 이를 위해서는반드시 먼저 두개의 집합이 연결을 할 수 있는 구조로 정렬되어야 하지만, 정렬을 해야 한다는 또 다른 부담을 안게됨.
* 비교 연산자가 '='이 아닌경우 Nested Loops보다 유리한 경우가 많다.
* Nested Loops Join과 달리 선행(Outer) 집합이라는 개념이 없다.

#### 3.2.2.3 Hash Join
*해쉬함수 기법을 활용하여 조인을 수행하는 방식이다. 해쉬함수는 컬럼의 값을 받아서 이 함수를 경유하면 로우의 저장위치를 리턴하는것이다.*
* Nested Loop (범위가 넓어질 때 랜덤 액세스로 큰 부하가 발생) > Sort Merge Join (정렬에 대한 부담은 데이터 양이 늘어날수록 크게 증가) > Hash Join(랜덤 액세스를 최소화하면서 정렬의 부담을 해결 - 해쉬함수로 연결될 대상을 특정 지역에 모아두는 역할만을 담당)
* 동일한 해쉬 값을 가진 데이터들을 모아둔 공간을 partition이라하고, 이들중에서 조인해야할 것들을 연결하게 되는데 이것을 Pair라 부른다.
* 연결작업을 위해 작은 파티션을 메모리 내에 임시적인 해쉬 테이블로 만든다.
* equijoin(동치조인) 일때만 가능하다.
* 대량 범위의 조인이나 테이블이 많은 조각으로 산재되어 있을때 유리

#### 3.2.2.4 Semi Join
*서브쿼리가 메인쿼리와 연결되는 모든 경우를 뜻하는 광의의 의미를 말함*
* 많은 경우의 서브쿼리는 조인 형식으로 실행계획이 나타난다.
* 그러나, 조인은 수평적인 관계있지만, 서브쿼리는 수직적인 관계에 있다. > 메인쿼리의 집합을 변형시켜서는 안된다라는 의미.
* 1:M, M:1 관계에서 메인쿼리가 M인경우는 조인과 동일한 방식으로 연결 하면 되지만, 서브쿼리가 M 집합일때는 일반적인 조인 방식으로 처리하면 메인쿼리의 집합이 달라지게 되므로 잘못된 결과를 얻는다. > 서브쿼리를 1 집합이 되도록 하면된다.
* 서브쿼리가 먼저 수행되어(Driving) Nested Loops형식이 되면 Sort(unique) 처리를 하여 메인 쿼리에 1 집합을 조인하게 한다. Sort Merge나 Hash Join 도 동일한 방식으로 처리 - 222페이지 참조
* 만약 M 집합을 가진 서브쿼리가 나중에 수행되면 ?? > 첫번째 연결에 성고하면 서브쿼리를 즉시 종료하면 된다. <= 이러한 처리를 Filter 형 처리라한다.

#### 3.2.2.5 Cartesian Join
*조인되는 두개의 집합간에 연결고리 조건이 전혀 없는 경우를 말한다. 혹은 M:M 조인을 의미한다.*

#### 3.2.2.6 Outer Join
*어떤 대상 집합을 기준으로 거기에 조인되어 있는 집합에 대해 로우가 없더라도 기준 집합의 모든 로우들을 리턴하는 조인이다.*
* Outer Join이라 불리는 이유는 외측 루프는 언제나 보존되고 내측 루프는 선택적인 조인이기 때문이다.
* Nested Loops Outer Join
	* 기준 집합이 외측 루프로써 먼저 수행이되어야 하면 내측 루프가 수행될때 연결에 실패를 하더라도 외측 루프의 로우를 탈락시키지 않는 방식으로 수행된다.
* Hash Outer Join
	* 기준 집합은 무조건 빌드입력(Build Input)을 담당하게 되고, 내측 조인 집합이 해쉬 테이블로 생성되어 연결작업이 수행된다.
* Sort Merge Outer Join
	* 조건 연산자로 인해 해쉬조인이 불가능할 때이거나 이미 다른 처리에 의해 조인을 위한 정렬이 선행되어 있어서 더 유리해질 때 적용된다.
* Full Outer Join
	* 양쪽 집합이 모두 기준집합이면서 대응집합이 되는 아우터 조인을 말한다.

#### 3.2.2.7 Index Join
*어떤 쿼리에서 특정 테이블에 사용된 모든 컬럼이 하나 이상의 인덱스들에 존재할 때 그 인덱스들 간의 해쉬 조인을 통해 액세스 하는 기법인다.*
* 235 페이지 이미지, 236 설명 참조
* 일반적으로 하나의 테이블 액세스에서 발생하는 현상이지만 다른 테이블과 조인하는 경우에도 조건을 만족하면 적용이 가능하다.

### 3.2.3 연상방식에 따른 실행계획
*때로는 보다나은 실행계획을 얻도록 하기 위해서 어떤 연산을 다른 형태로 변형하기도 한다.*
* IN-List 탐침(Iterator) 실행계획
* 연쇄(Concatenation) 실행계획
* 원격(Remote) 실행계획
* 정렬 처리 (Sort Operation)
* 합집합(Union, Union-all) 실행계획
* 교집합(Intersection) 실행계획
* 차집합(Minus) 실행계획
* COUNT(STOPKEY) 실행계획

#### 3.2.3.1 IN-List 탐침(Iterator) 실행계획
*IN 연산자를 사용하는 경우 IN은 여러개의 '='을 의미한다.*
* INLIST ITERATOR 실행계획은 IN 조건에 나열된 각각의 비교값 만큼 반복 수행한다는 것을 의미한다(240페이지)
* 옵티마이져는 IN연산을 OR 형태로 변겨시킨 후에 실행계획을 수립한다. 
* 처리주관 인덱스에 적용된 경우가 아니어서 단지 체크 기능만 담당한다면 이러한 실행계획은 나타나지 않는다.
* IN을 사용한 컬럼의 인덱스 선행 컬럼들이 모두 '='로 사용되어야 한다.
* IN 조건이 연속으로 나타난경우, 결합된 컬럼의 개수, IN 조건에 사용된 비교값이 상수나 변수, 서브쿼리일 때에 따라서 실행계획은 달라진다. 

#### 3.2.3.2 연쇄(Concatenation) 실행계획
*OR로 연결된 서로 다른 컬럼을 사용한 조건을 **별도의 실행단위**로 분리하여 각각의 최적의 액세스로 경로를 수립하여 이를 연결하는 실행계획을 말한다.*
* OR 조건이 처리주관 조건의 역할을 하는 경우만 실행계획이 되고 그렇지 않은경우 단순히 체크 조건으로만 사용된다.

#### 3.2.3.3 원격(Remote) 실행계획
*다른 데이터베이스의 테이블을 Database Link로 액세스하는 형태를 말한다.*
* 원격 실행계획의 세부 내용은 Library Cache 에서 얻을 수 있다. 
* 부담이 많은 원격 테이블이 외측 루프에서 수행되면 양호한 수행속도를 얻을 수 있지만, 내측 루프에서 수행된다면 매우 큰 부담이 된다.
* 원격 테이블 액세스는 랜덤이 아닌 범위처리에는 큰 부담이 없으므로 Sort Merge Join이나 Hash Join으로 나타나는 경우가 많다.
* 원격 액세스는 REMOTE 로만 나타마녀, 이는 원격 데이터베이스의 실행계획을 강제하지 못하기 때문이다. 

#### 3.2.3.4 정렬 처리(Sort Operation) 실행계획
* SORT(UNIQUE)
* SORT(AGGREGATE)
* SORT(GROUP BY)
* SORT(JOIN)
* SORT(ORDER BY)

	* SORT(UNIQUE)
		* DISTINCT를 사용했을때
		* 서브쿼리에서 제공자 역할을 할때 
    * SORT(AGGREGATE)
	    * GROUP BY 를 하지 않은 상태에서 전체 대상에 대해 그룹함수를 계산할때
	    * SUM, COUNT, AVG 는 정렬없이 각 로우를 대상으로 집계만 수행
	    * MIN, MAX도 동일하지만, 인덱스 선두컬럼으로 처리가 가능할 경우 인덱스의 첫번째 혹은 마지막 블록만 액세스하고 멈춘다.
    * SORT(GROUP BY)
    	* 여러개의 다름 그룹(GROUP)으로 집계(AGGREGATE)를 수행한다.
    	* GROUP BY구문에 의해 발생하며, 정렬을 수행할 수 밖에 없다. 
    	* 그룹의 개수가 많아질수록 부담이 커진다.
    	* 정렬작업은 데이터 량이 일정 수준을 초과하면 매우 부담이 많은 처리 방법이다. 이를 해결하기 위해 HASH(GROUP BY) 기능이 있다.
    	* 쿼리 처리 주관 인덱스의 선행컬럼이 GROUP BY 컬럼과 동일하면 별도의 SORT작업이 필요 없으므로 SORT(GROUP BY NOSORT) 실행계획을 세운다.

#### 3.2.3.5 집합 처리(Set Operations) 실행계획
* 합집합(Union, Union-All)
* 교집합(Intersection)
* 차집합(Minus)

	* 합집합(Union, Union-All) 실행계획
		* 복합한 액세스 처리를 몇 개로 분리함으로써 단순하게 처리할 수 있다.
		* Union은 두 집합을 단순하게 결합한 다음 반드시 SORT(UNIQUE)를 수행해야하지만, Union-All은 이런 처리가 필요 없다. 
    * 교집합(Intersection) 실행계획
    	* Sort Merge Join과 유사항 방법을 사용하여 양쪽 집합을 유일하게 정렬한 다음 이들을 머지하여 공통집합(최대공약수집합)을 리턴한다.
    * 차집합(Minus) 실행계획
    	* 한쪽 집합을 깆ㄴ으로 다른 집합의 요소들을 제거하는 집합이다. 
    	* 앞서 소개한 집합처리과 거의 유사하다.

#### 3.2.3.6 COUNT(STOPKEY) 실행계획
* 쿼리의 조건절에 ROWNUM을 사용했을 때 나타난다.
